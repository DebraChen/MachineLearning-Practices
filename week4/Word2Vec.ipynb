{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hmq-7x_y81wX"
   },
   "source": [
    "# Week 4.2 Lecture: Word2Vec Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQctzlnJ81wa"
   },
   "source": [
    "\n",
    "First, download the file from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g and place it in the same directory on your machine as this notebook.\n",
    "\n",
    "(If you're on colab, you'll need to follow the Moodle instructions to upload this file to your colab project.)\n",
    "\n",
    "Note that this will download a giant 1.5GB file onto your computer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L-7oJpIl81wb"
   },
   "outputs": [],
   "source": [
    "#Run this every time you run the notebook \n",
    "#Note that you may have to change the file path if you put it somewhere else (e.g., on colab)\n",
    "embeddings_file = \"GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Odcg6Zo81wc"
   },
   "source": [
    "Now, let's play!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PeAmdvB381wc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PYfYx5my81wc"
   },
   "outputs": [
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b'\\n\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadGzipFile\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#This line will load the 200,000 most common words into wv, a variable of word vectors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Note that this will load these into memory, so if you don't have a lot of memory on your computer you may run into problems/slowness\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m wv \u001b[38;5;241m=\u001b[39m \u001b[43mKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/gensim/models/keyedvectors.py:1629\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1582\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[1;32m   1584\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1585\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1586\u001b[0m     ):\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[1;32m   1588\u001b[0m \n\u001b[1;32m   1589\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \n\u001b[1;32m   1628\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/gensim/models/keyedvectors.py:1965\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1963\u001b[0m     fin \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1965\u001b[0m     header \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_unicode(\u001b[43mfin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[1;32m   1966\u001b[0m     vocab_size, vector_size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m header\u001b[38;5;241m.\u001b[39msplit()]  \u001b[38;5;66;03m# throws for invalid file format\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit:\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/gzip.py:390\u001b[0m, in \u001b[0;36mGzipFile.readline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadline\u001b[39m(\u001b[38;5;28mself\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_not_closed()\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/gzip.py:479\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_member:\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# If the _new_member flag is set, we have to\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# jump to the next member, if there is one.\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_read()\n\u001b[0;32m--> 479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_gzip_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/gzip.py:427\u001b[0m, in \u001b[0;36m_GzipReader._read_gzip_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\037\u001b[39;00m\u001b[38;5;130;01m\\213\u001b[39;00m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 427\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadGzipFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot a gzipped file (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m magic)\n\u001b[1;32m    429\u001b[0m (method, flag,\n\u001b[1;32m    430\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_mtime) \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BBIxx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_exact(\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m8\u001b[39m:\n",
      "\u001b[0;31mBadGzipFile\u001b[0m: Not a gzipped file (b'\\n\\n')"
     ]
    }
   ],
   "source": [
    "#This line will load the 200,000 most common words into wv, a variable of word vectors\n",
    "#Note that this will load these into memory, so if you don't have a lot of memory on your computer you may run into problems/slowness\n",
    "wv = KeyedVectors.load_word2vec_format(embeddings_file, binary=True, limit=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gEY1sn4s81wd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a word vector: \n",
      "(300,)\n",
      "Word vector for 'language':\n",
      "[ 2.30712891e-02  1.68457031e-02  1.54296875e-01  1.27929688e-01\n",
      " -2.67578125e-01  3.51562500e-02  1.19140625e-01  2.48046875e-01\n",
      "  1.93359375e-01 -7.95898438e-02  1.46484375e-01 -1.43554688e-01\n",
      " -3.04687500e-01  3.46679688e-02 -1.85546875e-02  1.06933594e-01\n",
      " -1.52343750e-01  2.89062500e-01  2.35595703e-02 -3.80859375e-01\n",
      "  1.09863281e-01  4.41406250e-01  3.75976562e-02 -1.22680664e-02\n",
      "  1.62353516e-02 -2.24609375e-01  7.61718750e-02 -3.12500000e-02\n",
      " -2.16064453e-02  1.49414062e-01 -4.02832031e-02 -4.46777344e-02\n",
      " -1.72851562e-01  3.32031250e-02  1.50390625e-01 -5.05371094e-02\n",
      "  2.72216797e-02  3.00781250e-01 -1.33789062e-01 -7.56835938e-02\n",
      "  1.93359375e-01 -1.98242188e-01 -1.27563477e-02  4.19921875e-01\n",
      " -2.19726562e-01  1.44531250e-01 -3.93066406e-02  1.94335938e-01\n",
      " -3.12500000e-01  1.84570312e-01  1.48773193e-04 -1.67968750e-01\n",
      " -7.37304688e-02 -3.12500000e-02  1.57226562e-01  3.30078125e-01\n",
      " -1.42578125e-01 -3.16406250e-01 -7.32421875e-02 -5.76171875e-02\n",
      "  1.02050781e-01 -1.08886719e-01  1.24023438e-01 -2.50244141e-02\n",
      " -2.49023438e-01  1.25976562e-01 -1.79687500e-01  3.32031250e-01\n",
      "  7.14111328e-03  2.51953125e-01  4.34570312e-02 -4.34570312e-02\n",
      " -3.90625000e-01  1.76757812e-01 -1.13525391e-02 -1.97753906e-02\n",
      "  2.79296875e-01  2.36328125e-01  1.19140625e-01  5.59082031e-02\n",
      "  1.73828125e-01 -1.10839844e-01 -4.95605469e-02  2.13867188e-01\n",
      "  6.17675781e-02  1.38671875e-01 -4.45556641e-03  2.55859375e-01\n",
      "  1.80664062e-01  5.88378906e-02 -6.59179688e-02 -2.08007812e-01\n",
      " -1.19140625e-01 -1.57226562e-01  5.02929688e-02 -6.29882812e-02\n",
      "  5.00488281e-02 -7.27539062e-02  1.74560547e-02 -3.56445312e-02\n",
      " -1.93359375e-01  3.93066406e-02 -3.36914062e-02 -1.07421875e-01\n",
      "  5.78613281e-02 -8.20312500e-02  1.74560547e-02 -1.65039062e-01\n",
      "  1.46484375e-01 -3.08837891e-02 -3.86718750e-01  2.49023438e-01\n",
      "  8.74023438e-02 -2.15820312e-01 -4.10156250e-02  1.60156250e-01\n",
      "  1.85546875e-01 -2.27050781e-02 -3.73535156e-02  7.86132812e-02\n",
      " -1.46484375e-01  6.78710938e-02  1.26953125e-01  3.30078125e-01\n",
      "  1.11328125e-01  9.27734375e-02 -3.45703125e-01 -1.41601562e-01\n",
      " -5.29785156e-02 -1.50390625e-01 -7.81250000e-02 -1.27929688e-01\n",
      " -4.02343750e-01 -1.41601562e-01  8.44726562e-02  1.08398438e-01\n",
      " -4.44335938e-02  3.73535156e-02  5.61523438e-02 -1.91406250e-01\n",
      "  1.54296875e-01 -5.12695312e-02 -6.49414062e-02 -8.30078125e-02\n",
      "  7.17773438e-02 -1.33789062e-01  1.05468750e-01  3.33984375e-01\n",
      " -1.08398438e-01  1.91650391e-02  2.14843750e-01  2.15820312e-01\n",
      " -1.05468750e-01 -1.44531250e-01  4.32128906e-02 -2.71484375e-01\n",
      " -3.78906250e-01  1.09863281e-01 -8.15429688e-02 -6.12792969e-02\n",
      " -1.33789062e-01  9.71679688e-02 -1.04370117e-02 -1.21093750e-01\n",
      " -2.44140625e-01  1.02050781e-01  1.10839844e-01 -1.00585938e-01\n",
      "  1.71875000e-01 -3.61328125e-02 -4.39453125e-02  2.83203125e-01\n",
      " -8.93554688e-02 -1.70898438e-01  2.46093750e-01  1.16699219e-01\n",
      "  8.39843750e-02 -1.32812500e-01 -1.61132812e-01 -1.39648438e-01\n",
      " -8.59375000e-02 -1.37695312e-01 -9.32617188e-02 -1.33789062e-01\n",
      "  1.65039062e-01  4.93164062e-02 -1.21093750e-01 -2.11914062e-01\n",
      "  1.61132812e-01 -1.07421875e-01 -3.97949219e-02 -3.51562500e-01\n",
      " -5.02929688e-02  1.46484375e-01 -4.68750000e-02  4.17480469e-02\n",
      " -1.27929688e-01 -9.76562500e-02 -2.46093750e-01  6.78710938e-02\n",
      " -2.30468750e-01  1.80664062e-02  3.54003906e-02  7.32421875e-02\n",
      " -2.23632812e-01 -1.25976562e-01  2.12890625e-01 -3.93066406e-02\n",
      " -2.41699219e-02 -9.61914062e-02  7.51953125e-02 -1.46484375e-01\n",
      " -1.49414062e-01 -8.83789062e-02 -4.88281250e-02  2.32421875e-01\n",
      "  3.30078125e-01  1.59179688e-01 -2.35351562e-01 -1.25976562e-01\n",
      "  2.68554688e-02 -5.29785156e-02 -6.59179688e-02 -2.17773438e-01\n",
      " -6.37817383e-03 -2.53906250e-01  2.28515625e-01  4.93164062e-02\n",
      "  3.54003906e-02  1.66992188e-01 -7.27539062e-02 -2.53906250e-01\n",
      " -1.34765625e-01  3.69140625e-01  1.83593750e-01 -1.64062500e-01\n",
      "  2.26562500e-01 -8.88671875e-02  3.69140625e-01  5.54199219e-02\n",
      " -3.63769531e-02 -1.48437500e-01  9.13085938e-02  2.47955322e-04\n",
      "  2.67578125e-01 -1.63085938e-01  1.19628906e-01  2.77343750e-01\n",
      " -1.49414062e-01  1.33789062e-01 -8.25195312e-02 -1.74804688e-01\n",
      " -1.77734375e-01  2.06054688e-01  5.07812500e-02 -2.08007812e-01\n",
      " -1.74804688e-01  9.66796875e-02  6.98242188e-02 -5.79833984e-04\n",
      "  9.22851562e-02  7.95898438e-02  1.41601562e-01  8.72802734e-03\n",
      " -8.05664062e-02  4.80957031e-02  2.49023438e-01 -1.64062500e-01\n",
      " -4.66308594e-02 -2.81250000e-01 -1.66015625e-01 -2.22656250e-01\n",
      " -2.32421875e-01  1.32812500e-01  4.15039062e-02  1.15234375e-01\n",
      " -7.66601562e-02 -1.10839844e-01 -1.97265625e-01  3.06396484e-02\n",
      " -1.03515625e-01  2.49023438e-02 -2.52685547e-02  3.39355469e-02\n",
      "  4.29687500e-02 -1.44531250e-01  2.12402344e-02  2.28271484e-02\n",
      " -1.88476562e-01  3.22265625e-01 -1.13281250e-01 -7.61718750e-02\n",
      "  2.94921875e-01 -1.33789062e-01 -1.80664062e-02 -6.25610352e-03\n",
      " -1.62353516e-02  5.98144531e-02  1.21582031e-01  4.17480469e-02]\n"
     ]
    }
   ],
   "source": [
    "#View the actual value of a vector for a word:\n",
    "# this is a 300-dimensional vector\n",
    "print(\"Shape of a word vector: \")\n",
    "print(np.shape(wv['language'])) #play around with other words\n",
    "print(\"Word vector for 'language':\")\n",
    "print(wv['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PAPGYXkr81wd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7609457\n",
      "0.6599656\n",
      "0.37941834\n",
      "0.03318137\n",
      "0.049963422\n",
      "-0.0038632862\n"
     ]
    }
   ],
   "source": [
    "#We can compare words by computing their cosine similarity\n",
    "# Try this out for different word pairs:\n",
    "print(wv.similarity('dog', 'cat'))\n",
    "print(wv.similarity('dog', 'terrier'))\n",
    "print(wv.similarity('dog', 'dolphin'))\n",
    "print(wv.similarity('dog', 'aubergine'))\n",
    "print(wv.similarity('dog', 'exuberant'))\n",
    "print(wv.similarity('dog', 'economics'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OiY0EO0781wd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dogs', 0.8680489659309387),\n",
       " ('puppy', 0.8106428384780884),\n",
       " ('pit_bull', 0.7803961038589478),\n",
       " ('pooch', 0.7627376914024353),\n",
       " ('cat', 0.7609457969665527),\n",
       " ('golden_retriever', 0.7500901818275452),\n",
       " ('German_shepherd', 0.7465174198150635),\n",
       " ('Rottweiler', 0.7437615394592285),\n",
       " ('beagle', 0.7418621778488159),\n",
       " ('pup', 0.7406911253929138)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for most similar words to a given word\n",
    "#Try this out for different words\n",
    "wv.most_similar(positive=['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rqzhpqYD81we"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brussels', 0.59405916929245),\n",
       " ('Berlin', 0.592768669128418),\n",
       " ('Amsterdam', 0.5912652015686035),\n",
       " ('Madrid', 0.5895830392837524),\n",
       " ('Frankfurt', 0.55706387758255),\n",
       " ('Parisian', 0.5517574548721313),\n",
       " ('Rome', 0.5313206911087036),\n",
       " ('Stockholm', 0.5250915884971619),\n",
       " ('Marrakesh', 0.5232300758361816),\n",
       " ('Strasbourg', 0.5227499604225159)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for most similar words to a set of words\n",
    "#wv.most_similar(positive=['potato', 'yam', 'yucca'])\n",
    "#wv.most_similar(positive=['croissant', 'donut'])\n",
    "wv.most_similar(positive=['London', 'Paris']) #Or maybe Camberwell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dasAHs1e81we",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ken_Livingstone', 0.7916719317436218),\n",
       " ('George_Osborne', 0.7817354798316956),\n",
       " ('Tony_Blair', 0.7768580317497253),\n",
       " ('Nick_Clegg', 0.7726122736930847),\n",
       " ('Alistair_Darling', 0.7554317712783813),\n",
       " ('Mr_Clegg', 0.7268158197402954),\n",
       " ('Chancellor_Alistair_Darling', 0.7248950004577637),\n",
       " ('Ed_Miliband', 0.7125200033187866),\n",
       " ('chancellor_Alistair_Darling', 0.7029644846916199),\n",
       " ('Ed_Balls', 0.7017458081245422)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try it with people\n",
    "wv.most_similar(positive=['Boris_Johnson','Gordon_Brown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1bOgIIR81we"
   },
   "outputs": [],
   "source": [
    "# Let's try answering a question via adding vectors: What is the football-like sport that Harry Potter plays?\n",
    "wv.most_similar(positive=['Harry_Potter','football'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72692oVt81wf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is the name of the school in Harry Potter?\n",
    "wv.most_similar(positive=['Harry_Potter','school'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwwWjY1L81wf"
   },
   "outputs": [],
   "source": [
    "# Now let's experiment with subtracting vectors...\n",
    "# the \"positive\" words point in the direction(s) you want to go; the \"negative\" words' vectors are subtracted from these\n",
    "\n",
    "#Example from powerpoint: goose + (dogs - dog)\n",
    "wv.most_similar(positive=['goose','dogs'],negative=['dog']) #It's geese!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4H6D9_-81wf"
   },
   "outputs": [],
   "source": [
    "#Another way of phrasing the above: Dog is to dogs as goose is to what?\n",
    "\n",
    "#Let's try some more\n",
    "# parts of speech: \"Longest is to long as slowest is to what?\"\n",
    "wv.most_similar(positive=['slowest','long'],negative=['longest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XKxHYG981wf"
   },
   "outputs": [],
   "source": [
    "# gender:\"man is to king as as woman is to what?\"\n",
    "wv.most_similar(positive=['woman','king'],negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOjNvCsq81wg"
   },
   "outputs": [],
   "source": [
    "#'man' minus 'woman' gives us a 'manly' vector. What happens when we subtract this vector from 'doctor'? \n",
    "wv.most_similar(positive=['woman','doctor'],negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrwLNlPL81wg"
   },
   "outputs": [],
   "source": [
    "#'man' minus 'woman' gives us a 'manly' vector. What happens when we ADD this vector to 'doctor'? \n",
    "# Can do this explicitly in vector math and get nearly the same result as most_similar function\n",
    "X = wv['man'] - wv['woman']\n",
    "v = (wv['doctor'] + X)\n",
    "wv.similar_by_vector(v) #grabs the most similar words to a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q76fVVdC81wg"
   },
   "outputs": [],
   "source": [
    "#Places: \"UK is to London as as France is to what?\"\n",
    "wv.most_similar(positive=['France','London'],negative=['UK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PhuF7cTo81wg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('croissant', 0.47772619128227234),\n",
       " ('scone', 0.46981364488601685),\n",
       " ('crisps', 0.4671917259693146),\n",
       " ('muffin', 0.45740562677383423),\n",
       " ('muesli', 0.44982248544692993),\n",
       " ('marmalade', 0.4486430287361145),\n",
       " ('puddings', 0.44180625677108765),\n",
       " ('lasagne', 0.43633562326431274),\n",
       " ('veg', 0.43387067317962646),\n",
       " ('kebab', 0.43329814076423645)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is the bagel of London?\n",
    "wv.most_similar(positive=['London','bagel'],negative=['New_York'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_Z7ewvR81wg"
   },
   "outputs": [],
   "source": [
    "#Who is the Marie Curie of music?\n",
    "wv.most_similar(positive=['Marie_Curie', 'music'],negative=['science'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbMKVh7I81wg"
   },
   "outputs": [],
   "source": [
    "#Finally, can search for things that don't match:\n",
    "wv.doesnt_match(\"dog cat lion rhino platypus\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0-LQ9dp81wh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#More exploration of bias\n",
    "print(wv.similarity('man', 'nurse'))\n",
    "print(wv.similarity('woman','nurse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqhkH6SL81wh"
   },
   "outputs": [],
   "source": [
    "print(wv.similarity('man', 'intelligent'))\n",
    "print(wv.similarity('woman', 'intelligent'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGzZPqzr81wh"
   },
   "outputs": [],
   "source": [
    "print(wv.similarity('man', 'competent'))\n",
    "print(wv.similarity('woman', 'competent'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sER97Dq81wh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(wv.similarity('man', 'attractive'))\n",
    "print(wv.similarity('woman', 'attractive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsngUU2L81wh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "qKgWOEun81wh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP Week 4.2-Word2Vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
