{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCJ92oYPJm3Z"
   },
   "source": [
    "# Exploring Machine Intelligence Week 4\n",
    "\n",
    "## Experiments with Image Autoencoders "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "we4JLggUMVvB"
   },
   "source": [
    "***Note 1***\n",
    "\n",
    "This notebook was originally written by Vit for the 2020 offering of Exploring Machine Intelligence. Vit in turn borrowed heavily from [https://blog.keras.io/building-autoencoders-in-keras.html](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "\n",
    "***Note 2***\n",
    "\n",
    "It is strongly recommended to run this on colab.google.com if you do not have a GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Set everything up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1ExBFHWSkoa"
   },
   "outputs": [],
   "source": [
    "# Run this code without any changes\n",
    "# Basic imports\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\n",
    "from keras.layers import Reshape, Flatten, BatchNormalization, Activation\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
    "# z = z_mean + sqrt(var) * epsilon\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeQy4OM0ucTd"
   },
   "source": [
    "# Step 1: Load the data using Option 1 or Option 2 below. (Start with Option 1, then move onto Step 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sppEfI7KJm3b"
   },
   "source": [
    "### Option 1: Use MNIST digits (Start here first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPRLTu6HSks2"
   },
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "#original_dim = image_size * image_size\n",
    "#x_train = np.reshape(x_train, [-1, original_dim])\n",
    "#x_test = np.reshape(x_test, [-1, original_dim])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "input_shape = x_train[0].shape\n",
    "x_train = np.reshape(x_train, x_train.shape+(1,))\n",
    "x_test = np.reshape(x_test, x_test.shape+(1,))\n",
    "\n",
    "print(\"We loaded the MNIST dataset:\")\n",
    "print(\"input_shape:\", input_shape)\n",
    "print(\"x_train:\", x_train.shape)\n",
    "print(\"x_test:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4J-gVgPojaVj"
   },
   "outputs": [],
   "source": [
    "# Let's look at one sample:\n",
    "x1 = x_test[9000] #looks at the 9000th sample\n",
    "print(x1.shape, \"stats:\", np.max(x1), np.min(x1), np.mean(x1))\n",
    "\n",
    "#Show it as an image:\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(x1[:,:,0], cmap='gray', vmin=0.0, vmax=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNy-Jyw8u7B3"
   },
   "source": [
    "### Option 2: Use QuickDraw (Do this only after you've done MNIST)\n",
    "\n",
    "We can also use the QuickDraw [dataset](https://github.com/googlecreativelab/quickdraw-dataset) by [@Zaid Alyafeai](https://twitter.com/zaidalyafeai) which was used in the [ML4A guide](https://ml4a.github.io/guides/) for regular AutoEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyEhhOm4u9KN"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/zaidalyafeai/QuickDraw10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Caqwx8IfvEHf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data = np.load('QuickDraw10/dataset/train-ubyte.npz')\n",
    "test_data  = np.load('QuickDraw10/dataset/test-ubyte.npz')\n",
    "\n",
    "x_train, y_train = train_data['a'], test_data['b']\n",
    "x_test,  y_test  = test_data['a'],  test_data['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tZ0S35UvGI-"
   },
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train.astype('float32') / 255., 3)\n",
    "x_test =  np.expand_dims(x_test.astype('float32') / 255. , 3)\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xzh6c1fH_3r1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at one sample:\n",
    "x1 = x_test[0] # 0 - umbrella\n",
    "print(x1.shape, \"stats:\", np.max(x1), np.min(x1), np.mean(x1))\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(x1[:,:,0], cmap='gray', vmin=0.0, vmax=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that you've loaded the data, you can re-run the rest of the notebook to build a model, interpolate, etc!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UksXjRH1jr1k"
   },
   "source": [
    "# Step 2: Now that you've loaded data (either MNIST or QuickDraw), do this to build the model:\n",
    "\n",
    "Ensure that you've chosen either the MNIST or QuickDraw dataset above, and the dataset you want is now loaded into `x_train` and `x_test`.\n",
    "\n",
    "This code builds a model using a standard convolutional autoencoder architecture:\n",
    "\n",
    "Image -> Encoder -> latent vector representation -> Decoder -> Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAYt9EoQSoO9"
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (28, 28, 1)\n",
    "latent_dim = 32 #you might play with changing this\n",
    "\n",
    "# VAE model = encoder + decoder\n",
    "\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "\n",
    "kernels = 26 #you could change this too\n",
    "\n",
    "x = Conv2D(kernels, (3), activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling2D((2), padding='same')(x)\n",
    "x = Conv2D(int(kernels/2), (3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2), padding='same')(x)\n",
    "x = Conv2D(int(kernels/4), (3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2), padding='same')(x)\n",
    "intermediate_conv_shape = x.get_shape()\n",
    "x = Flatten()(x)\n",
    "\n",
    "# optionally BN?\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "_,n,m,o = intermediate_conv_shape # (None, 4, 4, 6) # 96\n",
    "intermediate_dim = n*m*o\n",
    "\n",
    "#some fully connected layers in the middle?\n",
    "#x = Dense(intermediate_dim, activation='relu')(x)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "\n",
    "# optionally BN?\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = Reshape((n,m,o))(x)\n",
    "x = Conv2D(int(kernels/4), (3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2))(x)\n",
    "x = Conv2D(int(kernels/2), (3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2))(x)\n",
    "x = Conv2D(int(kernels), (3), activation='relu')(x)\n",
    "x = UpSampling2D((2))(x)\n",
    "outputs = Conv2D(1, (3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUzK4Q2r5YSG"
   },
   "outputs": [],
   "source": [
    "encoder.summary()\n",
    "#plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
    "decoder.summary()\n",
    "#plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QHpzrXMb582"
   },
   "outputs": [],
   "source": [
    "models = (encoder, decoder)\n",
    "data = (x_test, y_test)\n",
    "\n",
    "args_mse = False\n",
    "# VAE loss = mse_loss or xent_loss + kl_loss\n",
    "if args_mse:\n",
    "    reconstruction_loss = mse(inputs, outputs)\n",
    "else:\n",
    "    reconstruction_loss = binary_crossentropy(inputs, outputs)\n",
    "\n",
    "m = input_shape[0]*input_shape[1]\n",
    "reconstruction_loss *= m # 28x28 values\n",
    "reconstruction_loss = K.sum(reconstruction_loss)\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae_loss /= m\n",
    "vae_loss /= m\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xG6_I67YjCl"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "#history = vae.fit(x_train[0:1000], epochs=epochs, shuffle=True, batch_size=batch_size, validation_data=(x_test, None))\n",
    "history = vae.fit(x_train, epochs=epochs, shuffle=True, batch_size=batch_size, validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hz30ZMO72R26"
   },
   "outputs": [],
   "source": [
    "# How did we go?\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs_array = list(range(epochs))\n",
    "plt.plot(epochs_array, loss, label=\"loss\")\n",
    "plt.plot(epochs_array, val_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "\n",
    "print(\"Plot:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYVkB_L7ZfqF"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_model(model, name):\n",
    "    model_json = model.to_json()\n",
    "    with open(name+\".json\", \"w\") as json_file:\n",
    "        json.dump(model_json, json_file)\n",
    "\n",
    "    model.save_weights(name+\".h5\")\n",
    "\n",
    "#you might want to give your model an understandable filename\n",
    "save_model(encoder,'encoder_mnist')\n",
    "save_model(decoder,'decoder_mnist')\n",
    "#save_model(encoder,'encoder_draw_10ep')\n",
    "#save_model(decoder,'decoder_draw_10ep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9fI5yDycZWK"
   },
   "source": [
    "## Now let's use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzcFS5eUnQpW"
   },
   "outputs": [],
   "source": [
    "# We can carry these files (*.h5, *.json) somewhere else ...\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "def my_load_model(name):\n",
    "    with open(name+'.json','r') as f:\n",
    "        model_json = json.load(f)\n",
    "\n",
    "    model = model_from_json(model_json)\n",
    "    model.load_weights(name+'.h5')\n",
    "    return model\n",
    "\n",
    "#Use same filename as above here\n",
    "decoder = my_load_model('decoder_mnist')\n",
    "encoder = my_load_model('encoder_mnist')\n",
    "#decoder = my_load_model('decoder_draw_10ep')\n",
    "#encoder = my_load_model('encoder_draw_10ep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuxxAjg9vj4s"
   },
   "source": [
    "## Inspect one in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANTzSexmcbOO"
   },
   "outputs": [],
   "source": [
    "# Encoded image:\n",
    "\n",
    "x1 = x_test[73] # number 73 picked for no reason at all\n",
    "print(x1.shape)\n",
    "print(np.max(x1), np.min(x1), np.mean(x1))\n",
    "\n",
    "img = x1[:,:,0]\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(img, cmap='gray', vmin=0.0, vmax=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtM6GCDXcmZz"
   },
   "outputs": [],
   "source": [
    "# Latent vector:\n",
    "\n",
    "x1_arr = np.asarray([x1])\n",
    "z, z_mean, z_log_var = encoder.predict(x1_arr)\n",
    "print(z.shape)\n",
    "print(np.max(z), np.min(z), np.mean(z))\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(z[0])\n",
    "plt.show()\n",
    "\n",
    "#Plotting is not particularly informative here, it's just a set of 32 numbers, but why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwZcDisYcn7K"
   },
   "outputs": [],
   "source": [
    "# Reconstructed image\n",
    "\n",
    "y1 = decoder.predict(z)\n",
    "print(y1.shape)\n",
    "y1 = y1[0]\n",
    "\n",
    "img = y1[:,:,0]\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(img, cmap='gray', vmin=0.0, vmax=1.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29OmI-qhvnwp"
   },
   "source": [
    "## Or in triplets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWdrzugZo69j"
   },
   "outputs": [],
   "source": [
    "def plot_tripple(image, vector, reconstruction):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    fig.suptitle('Image > Representation > Reconstruction')\n",
    "    ax1.imshow(image, cmap='gray', vmin=0.0, vmax=1.0)\n",
    "    ax2.plot(vector)\n",
    "    ax2.set_aspect(3.1)\n",
    "    ax3.imshow(reconstruction, cmap='gray', vmin=0.0, vmax=1.0)\n",
    "\n",
    "def plot_single(image):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(image, cmap='gray', vmin=0.0, vmax=1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exteRSHpegnF"
   },
   "outputs": [],
   "source": [
    "x1 = x_test[9] # Randomly pick 9th image from test set\n",
    "z, z_mean, z_log_var = encoder.predict(np.asarray([x1])) \n",
    "y1 = decoder.predict(z)\n",
    "\n",
    "plot_tripple(x1[:,:,0], z[0], y1[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MO8oh8EgJm3j"
   },
   "source": [
    "### Look at a few randomly selected images and compare original, latent vector, and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GSfZrPB4oRv"
   },
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "for i in range(5):\n",
    "    x1 = x_test[randrange(len(x_test))]\n",
    "    z, z_mean, z_log_var = encoder.predict(np.asarray([x1]))\n",
    "    y1 = decoder.predict(z)\n",
    "    plot_tripple(x1[:,:,0], z[0], y1[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKxt3PC4Jm3j"
   },
   "source": [
    "### Show interpolation/moprhing between two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjznXdDppCsW"
   },
   "outputs": [],
   "source": [
    "sample_a = x_test[2] \n",
    "z_sample_a_encoded, _, _ = encoder.predict(np.asarray([sample_a]))\n",
    "\n",
    "sample_b = x_test[3] \n",
    "z_sample_b_encoded, _, _ = encoder.predict(np.asarray([sample_b]))\n",
    "\n",
    "print(\"z_sample_a_encoded:\", z_sample_a_encoded.shape)\n",
    "print(\"z_sample_b_encoded:\", z_sample_b_encoded.shape)\n",
    "\n",
    "#Let's show both original images \n",
    "plot_single(sample_a.reshape((28,28)))\n",
    "plot_single(sample_b.reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncN_5Upp4xGp"
   },
   "outputs": [],
   "source": [
    "# Show the latent vectors for each image\n",
    "plt.plot(z_sample_a_encoded[0])\n",
    "plt.show()\n",
    "plt.plot(z_sample_b_encoded[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDSl4UenprOf"
   },
   "outputs": [],
   "source": [
    "# Define a function to linearly interpolate from one latent vector for another,\n",
    "# specifically a*100% of the way there (i.e., if a=0.25, then we'll be 25% of the way from a to b)\n",
    "def lerp(u,v,a):\n",
    "    # linear interpolation between vectors u and v\n",
    "    return a*u + (1-a)*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "is6HM7AGqYnZ"
   },
   "outputs": [],
   "source": [
    "a = 0.5  #show one image halfway between a and b\n",
    "z_mix = lerp(z_sample_a_encoded, z_sample_b_encoded, a)\n",
    "image = decoder.predict(z_mix) # shape comes as (1,28,28,1)\n",
    "image = image.reshape((28,28))\n",
    "\n",
    "plot_single(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qmU61nrp1KL"
   },
   "outputs": [],
   "source": [
    "# Now interpolate in a set number of steps\n",
    "steps = 5\n",
    "for i in range(steps + 1):\n",
    "    # Goes from 0.0 to 1.0 in <steps> steps\n",
    "    a_01 = float(i) / float(steps)\n",
    "    z_mix = lerp(z_sample_a_encoded, z_sample_b_encoded, a_01)\n",
    "    y = decoder.predict(z_mix)\n",
    "    image = y.reshape((28,28))\n",
    "    print(a_01,\":\")\n",
    "    plot_single(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufq8zbduB2wj"
   },
   "source": [
    "## Produce a new image from a completely random latent vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xR8vmMyIB5SP"
   },
   "outputs": [],
   "source": [
    "# Random latent\n",
    "latent = np.random.randn(1, 32) * 5\n",
    "print(\"latent = \",latent)\n",
    "\n",
    "image = decoder.predict(latent)\n",
    "image = image.reshape((28,28))\n",
    "\n",
    "plot_single(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSzFK4pMChn7"
   },
   "outputs": [],
   "source": [
    "# We can try to break it ...\n",
    "\n",
    "latent = np.zeros(32)\n",
    "latent[0] = 999.0 # oversaturated?\n",
    "print(\"latent = \",latent)\n",
    "\n",
    "image = decoder.predict(latent.reshape(1,32))\n",
    "image = image.reshape((28,28))\n",
    "\n",
    "plot_single(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucy3KNYCz4t_"
   },
   "source": [
    "## (Or) visualization as a gif:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZs9kqpq1Ate"
   },
   "source": [
    "As a bonus including a visualization from https://github.com/zaidalyafeai/Notebooks/blob/master/AutoEncoders.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you'll need to install `imageio` and `opencv-python` modules using pip or conda (see moodle instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3Otq7F2z6j6"
   },
   "outputs": [],
   "source": [
    "import shutil \n",
    "import cv2\n",
    "import imageio, glob\n",
    "\n",
    "#linear interpolation function \n",
    "def f(x):\n",
    "  return x\n",
    "\n",
    "def interpolate(size = 10):\n",
    "  if os.path.exists(\"images\"):\n",
    "    shutil.rmtree(\"images\")\n",
    "    os.makedirs('images')\n",
    "  else:\n",
    "    os.makedirs('images')\n",
    "    \n",
    "  \n",
    "  \n",
    "  #get 3 random batches each of size 3 \n",
    "  batches = []\n",
    "  for _ in range(0, 3):\n",
    "    i1 = np.random.randint(0, len(x_train))\n",
    "    i2 = np.random.randint(0, len(x_train))\n",
    "    batches.append([x_train[i1:i1+3], x_train[i2:i2+3]])\n",
    " \n",
    "  i = 0   \n",
    "  for x in list(np.linspace(0, 1, size)):\n",
    "    frame = None\n",
    "    j = 0 \n",
    "    \n",
    "    #interpolate each batch and concatenate them at the end to create 3x3 images\n",
    "    for (x1, x2) in batches:\n",
    "    \n",
    "      \n",
    "      v1,_,_ = encoder.predict(x1) \n",
    "      v2,_,_ = encoder.predict(x2)\n",
    "        \n",
    "      #use a linear interpolater\n",
    "      v = (float(x))*v1 + (1.0 - float(x))*v2\n",
    "      \n",
    "      #get the output and reshape it \n",
    "      y = decoder.predict(v)\n",
    "      img = np.reshape(y, (3 * 28, 28))\n",
    "      img = img * 255\n",
    "      \n",
    "      #concatenate the batches \n",
    "      if frame is None:\n",
    "        frame = img\n",
    "      else:\n",
    "        frame = np.concatenate([frame, img], axis = 1)\n",
    "      j += 1\n",
    "      \n",
    "    #write the current frame to the disk \n",
    "    frame = cv2.resize(frame, (256, 256))  \n",
    "    cv2.imwrite(f'images/image{i}.png', frame)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxMnWyHm0BOS"
   },
   "outputs": [],
   "source": [
    "!mkdir images\n",
    "!ls images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TUsXYTg05gQ"
   },
   "outputs": [],
   "source": [
    "interpolate(size = 10)\n",
    "\n",
    "with imageio.get_writer('lsi.gif', mode='I', duration=0.35) as writer:\n",
    "  filenames = glob.glob('images/image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  \n",
    "  for i,filename in enumerate(filenames):\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "    \n",
    "# this is a hack to display the gif inside the notebook\n",
    "os.system('cp lsi.gif lsi.gif.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5Ob-whl3CYJ"
   },
   "outputs": [],
   "source": [
    "from IPython import display \n",
    "display.Image(filename=\"lsi.gif.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFyrQNH43C4N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLu-j3lhS579"
   },
   "source": [
    "## Activities to do on your own\n",
    "1. (Easy) Try modifying the autoencoder or its training in at least one way that gives you a noticeable impact on the results. (e.g., change the optimiser, the number of kernels, the number of layers, the dimensionality of the latent vector, the activation function, etc.) How does this impact on the results? What changes did you try that did not impact the results noticably?\n",
    "2. (More difficult) Try training this autoencoder on a new dataset. For instance, you might grab an existing image dataset from [https://www.kaggle.com/datasets?tags=13207-Computer+Vision](https://www.kaggle.com/datasets?tags=13207-Computer+Vision). You will have to tweak the code above if your images are a different size other than 28x28 (it's unwise to use images that are significantly bigger than this, though, unless you are willing to wait a while for training!)\n",
    "3. (More difficult) Try building a version of Mario Klingemann's \"X Degrees of Separation\" for a dataset (could be MNIST or QuickDraw or something else). Write the code to select 5 (or some other number) of existing images that follow a smooth (as smooth as possible) path through latent space between two chosen images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hb50G7RS8Ok"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5.1_convolutional_VAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
